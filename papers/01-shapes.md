# Shapes and frictions of synthetic dataShapes and frictions of synthetic data

Offenhuber
2024

## Summary

Synthetic data—artificially generated data that mimic real-world observations—has become an increasingly prominent practice in fields ranging from machine learning and simulation to government statistics and policy. Although originally designed to protect privacy or augment scarce datasets, synthetic data now appears in diverse applications such as large-scale AI training, medical imaging, census data, and social media simulations. This rapid adoption challenges traditional assumptions about how data represent the world.

The paper critiques what it calls the _representational model_ of data, where each datum is assumed to mirror a real-world object. Synthetic data often break this mirroring altogether: they may have no direct empirical referent, are tailored for specific tasks (e.g., training a classifier), and are frequently generated by opaque AI models. Consequently, issues of bias, privacy, and trust become harder to diagnose and address, since one cannot simply compare synthetic records to “ground truth.”

The author proposes a _relational model_ in which data must be understood in context—by _who_ uses them, _how_, and _for what purpose_. Rather than measuring a dataset’s fidelity to real-world observations, this perspective weighs its performance in a given scenario, the goals driving its creation, and the form of evidence demanded by its stakeholders. In practice, synthetic data must address a trade-off among privacy (protecting individual identities), fairness (avoiding biased outcomes), and utility (preserving statistical properties needed for modeling). Techniques like differential privacy, noise injection, data augmentation, and inpainting can mitigate some concerns yet introduce new frictions, for example through lost information, masked outliers, or inadvertent distortions of minority groups.

A recurring theme is that synthetic data can make analysis deceptively _easier_—data are conveniently produced at any desired volume or distribution—while simultaneously obscuring crucial details about how these data relate to the real world. This “airbrushing” of anomalies and irregularities can remove exactly those signals researchers or auditors need to uncover systemic issues, rare events, or manipulations. Despite promising uses, such as bolstering AI training in low-data regimes and protecting personal information, the paper warns that synthetic data demand vigilance. Researchers should attend to their generation and validation processes, the trade-offs they encode, and their ethical ramifications.

Ultimately, synthetic data highlight the speculative and purpose-driven nature of all data. Moving beyond representations toward relational understandings uncovers how data are enacted and interpreted across contexts—a critical step for ensuring that synthetic data foster responsible knowledge production rather than simply accelerate “anything goes” automation.
